# Porjet_Scrapping
Description
Ce projet a pour objectif de scrapper des sites web pour récupérer des données d'articles, telles que les titres, catégories, vues, et autres informations pertinentes. Les données sont ensuite traitées, combinées et analysées pour produire des rapports de performance des sites.

Structure du projet
Dossier data :
Contient les fichiers Excel générés lors du scraping, ainsi que le fichier combiné final qui regroupe toutes les données extraites.

Dossier liens :
Contient les rapports HTML de chaque page scrappée, permettant de visualiser les données extraites de chaque site.

Fonctionnalités principales
Scraping des articles :
Le script récupère les informations sur les articles publiés sur les sites cibles, incluant le titre, la description, la catégorie, les vues, et d'autres métadonnées.

Traitement des données :
Les données collectées sont nettoyées et organisées, supprimant les lignes vides et filtrant les valeurs inutiles.

Combinaison des données :
Les fichiers issus du scraping sont fusionnés dans un fichier de sortie final pour permettre une analyse complète et une visualisation des données.

Analyse et rapport :
Des analyses sont réalisées sur les données pour produire des rapports sur la performance des sites, avec des visualisations des métriques clés comme le nombre d'articles, les vues quotidiennes, et la performance par catégorie.

Prérequis
Python 3.x
Bibliothèques Python : BeautifulSoup, Pandas, Requests, Matplotlib, Seaborn, Power BI
Git pour le contrôle de version


